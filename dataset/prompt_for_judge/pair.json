{
    "translation_pair_prompt": "You are tasked with comparing two translations from ##SOURCE_LAN## to ##TARGET_LAN## based on the following criteria:\n\n- **Accuracy**: How well does each ##TARGET_LAN## translation convey the meaning of the original ##SOURCE_LAN## text?\n- **Fluency**: Is each ##TARGET_LAN## translation natural and grammatically correct?\n- **Consistency**: Does each translation maintain the same tone and style as the original ##SOURCE_LAN## text?\n- **Cultural Appropriateness**: Is each translation culturally appropriate for ##TARGET_LAN##-speaking audiences?\n- **Adherence to Feedback**: Does each translation follow any specific instructions or feedback provided?\n\nPlease compare the two translations and determine which one is better overall based on the criteria above.\n\n**Original ##SOURCE_LAN## Text**:\n##SOURCE##\n\n**Translation A in ##TARGET_LAN##**:\n##A##\n\n**Translation B in ##TARGET_LAN##**:\n##B##\n\nPlease select the better translation by responding with either \"A\", \"B\", or \"Tie\".\n\n**Important Notes:**\nOnly give me the answer \"A\", \"B\", or \"Tie\". Do not provide any explanation or annotation or other words.",
    "translation_pair_prompt_vanilla": "You are a helpful assistant. You need to perform a translation task(##SOURCE_LAN## to ##TARGET_LAN##). \nYou aim to evaluate the quality of the responses for a given instruction. Your goal is to select the best response for the given instruction. Select Response A or Response B for the given instructions. The two outputs are generated by two different AI chatbots respectively. \nDo NOT provide any explanation for your choice. Do NOT say both / neither are good. You should answer using ONLY \"A\" or \"B\". Do NOT output any other words. \n# Instruction: \n##SOURCE##\n# Response A: \n##A##\n# Response B: \n##B##\n# Which is better, Response A or Response B? Your response should be either \"A\" or \"B\":\n",
    "translation_pair_prompt_hard": "Please act as an impartial judge. You need to perform a translation task(##SOURCE_LAN## to ##TARGET_LAN##). \nYour goal is to evaluate the quality of the responses provided by two AI assistants to the user prompt displayed below. You will be given Response A and Response B from the assistants. Your job is to evaluate which response is better. \nBegin your evaluation by generating your own response to the prompt. You must provide your responses before judging any responses. When evaluating the assistants' responses, compare both assistants' responses with your response. You must identify and correct any mistakes or inaccurate information. \nPlease consider if the responses are helpful, relevant, and concise. Helpful means the response correctly responds to the prompt or follows the instructions. Note when user prompt has any ambiguity or more than one interpretation, it is more helpful and appropriate to ask for clarifications or more information from the user than providing an response based on assumptions. Relevant means all parts of the response closely connect or are appropriate to what is being asked. Concise means the response is clear and not verbose or excessive. Then consider the creativity and novelty of the responses when needed. Finally, identify any missing important information in the responses that would be beneficial to include when responding to the user prompt. \nPlease provide your explanation before providing your preference.\nThen you must output only one of the following choices as your final verdict with a label: 1. A: Response A is significantly better [[A>>B]] 2. A: Response A is slightly better [[A>B]] 3. Tie: relatively the same [[A=B]] 4. B: Response B is slightly better [[B>A]] 5. B: Response B is significantly better [[B>>A]] Example output: \"Tie: [[A=B]]\". \nUser Prompt:\n <|User Prompt|> ##SOURCE##\n<|The Start of Response A|>\n ##A##\n <|The End of Response A|>\n<|The Start of Response B|> \n##B##\n<|The End of Response B|>\n",
    "translation_pair_prompt_google-vertex": "You are an expert evaluator. You need to perform a translation task(##SOURCE_LAN## to ##TARGET_LAN##). \nYour task is to evaluate the quality of the responses generated by two AI models. We will provide you with the user input and a pair of AI-generated responses (Response A and Response B). You should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below. \nMetric Definition: You will be assessing question answering quality, which measures the overall quality of the answer to the question in the user prompt. Pay special attention to length constraints, such as in X words or in Y sentences. The instruction for performing a question-answering task is provided in the user prompt. The response should not contain information that is not present in the context (if it is provided). You need to consider the following criteria. Instruction following: The response demonstrates a clear understanding of the question answering task instructions, satisfying all of the instruction's requirements. Groundedness: The response contains information included only in the context if the context is present in the user prompt. The response does not reference any outside information. Completeness: The response completely answers the question with sufficient detail. Fluent: The response is well-organized and easy to read. \nYou will first judge responses individually, following the Rating Rubric and Evaluation Steps. Then you will give step-by-step explanations for your judgment, compare results to declare the winner based on the Rating Rubric and Evaluation Steps. Evaluation Steps: STEP 1: Analyze Response A based on the question answering quality criteria: Determine how well Response A fulfills the user requirements, is grounded in the context, is complete and fluent, and provides assessment according to the criterion. STEP 2: Analyze Response B based on the question answering quality criteria: Determine how well Response B fulfills the user requirements, is grounded in the context, is complete and fluent, and provides assessment according to the criterion. STEP 3: Compare the overall performance of Response A and Response B based on your analyses and assessment. STEP 4: Output your preference of\"A\" or \"B\" or \"Tie\" to the pairwise choice field according to the Rating Rubric. STEP 5: Output your assessment reasoning in the explanation field. \n3. Rating Rubric:\"A\": Response A answers the given question as per the criteria better than response B. \"Tie\": Response A and B answers the given question equally well as per the criteria. \"B\": Response B answers the given question as per the criteria better than response A.\nUser Inputs: \nPrompt:\n##SOURCE##\nAI-generated Response:\n Response A: \n##A##\nResponse B:\n##B##\n",
    "translation_pair_prompt_ours": "You are a fair judge assistant. You need to perform a translation task(##SOURCE_LAN## to ##TARGET_LAN##). \nPlease directly output your final verdict by strictly following this format: \"[[A]]\" if assistant A is better, \"[[B]]\" if assistant B is better. \nPlease consider the helpfulness, relevance, accuracy, and level of detail of their responses. \nPlease provide your explanation before providing your preference. \n###Instruction: \n##SOURCE## ###Response A: \n##A## \n###Response B: \n##B##",
    "translation_pair_prompt_ours-hard": "You are an expert evaluator.  You need to perform a translation task(##SOURCE_LAN## to ##TARGET_LAN##).  \nYou aim to evaluate the quality of the responses for a given instruction.  Your goal is to select the best response for the given instruction.  Select Response A or Responses B for the given instructions.  The two outputs are generated by two different AI chatbots respectively.  \nBegin your evaluation by generating your own response to the prompt.  You must provide your responses before judging any responses.  When evaluating the assistants' responses, compare both assistants' responses with your response.  You must identify and correct any mistakes or inaccurate information.  \nPlease consider the helpfulness, relevance, accuracy, and level of detail of their responses.  \nPlease provide your explanation before providing your preference.  \n###Instruction: \n##SOURCE## \n###Response A: \n##A## \n###Response B: \n##B##",
    "code2code_pair_prompt": "You are tasked with comparing two ##TARGET_CODE## code translated from ##SOURCE_CODE## code, based on the following criteria:\n\n- **Correctness**: Does the ##TARGET_CODE## code produces the same output as the ##SOURCE_CODE## code for all given inputs and edge cases?\n- **Functionality**: Does the ##TARGET_CODE## code fully implement the intended functionality of the ##SOURCE_CODE## code without omissions or deviations?\n- **Readability**: Is the ##TARGET_CODE## code clear, well-structured, and easy to understand, with consistent naming conventions and proper formatting?\n- **Performance**: Does the ##TARGET_CODE## code maintain or improve the efficiency of the ##SOURCE_CODE## code in terms of time and space complexity?\n- **Consistency**: Does the ##TARGET_CODE## code adheres to the same logic, structure, and style as the ##SOURCE_CODE## code, ensuring a seamless translation?\n\nPlease compare the two translated code and determine which one is better overall based on the criteria above.\n\n**Original ##SOURCE_CODE## Code**:\n##SOURCE##\n\n**Translated code A in ##TARGET_CODE##**:\n##A##\n\n**Translated code B in ##TARGET_CODE##**:\n##B##\n\nPlease select the better translated code by responding with either \"A\", \"B\", or \"Tie\".\n\n**Important Notes:**\nOnly give me the answer \"A\", \"B\", or \"Tie\". Do not provide any explanation or annotation or other words.",
    "text2code_pair_prompt": "You are tasked with comparing two code generated from the original text, based on the following criteria:\n\n -**Correctness**: Does the code accurately reflects the logic and requirements described in the text?\n- **Functionality**: Does the code fully implement the intended functionality without omissions or deviations from the text?\n- **Readability**: Is the code clear, well-structured, and easy to understand, with consistent naming and proper formatting?\n- **Maintainability**: Is the code modular, reusable, and easy to extend or modify, aligning with the text's intent?\n- **Robustness**: Does the code handle edge cases, errors, and unexpected inputs gracefully, as implied by the text?\n\nPlease compare the two generated code and determine which one is better overall based on the criteria above.\n\n**Original Text**:\n##SOURCE##\n\n**Generated Code A**:\n##A##\n\n**Generated Code B**:\n##B##\n\nPlease select the better code by responding with either \"A\", \"B\", or \"Tie\".\n\n**Important Notes:**\nOnly give me the answer \"A\", \"B\", or \"Tie\". Do not provide any explanation or annotation or other words.",
    "code2text_pair_prompt": "You are tasked with comparing two descriptions of the given code, based on the following criteria:\n\n- **Accuracy**: Does the description correctly and precisely explain the functionality, logic, and behavior of the code?\n- **Clarity**: Is the description clear, concise, and easy to understand, avoiding jargon or unnecessary complexity?\n- **Completeness**: Does the description cover all critical aspects of the code, including purpose, inputs, outputs, and edge cases?\n- **Relevance**: Does the description focus on the most important and relevant details of the code, omitting trivial or unrelated information?\n- **Consistency**: Does the description align with the code's structure, logic, and intent, ensuring a faithful representation?\n\nPlease compare the two descriptions and determine which one is better overall based on the criteria above.\n\n**Code**:\n##SOURCE##\n\n**Description A**:\n##A##\n\n**Description B**:\n##B##\n\nPlease select the better one by responding with either \"A\", \"B\", or \"Tie\".\n\n**Important Notes:**\nOnly give me the answer \"A\", \"B\", or \"Tie\". Do not provide any explanation or annotation or other words.",
    "math_pair_prompt": "You are tasked with comparing two solutions of the given math or reasoning problem, based on the following criteria:\n\n- **Correctness (4.0 pts)**: Final answer and all intermediate steps are mathematically accurate. No calculation or logical errors.\n- **Rigorousness (2.5 pts)**: Key steps are fully justified (e.g., theorems cited, assumptions stated). Solutions handle edge cases and constraints appropriately.\n- **Completeness (2.0 pts)**: All critical problem-solving steps are explicitly shown. Answers fully address the original question.\n- **Standard Compliance (1.0 pts)**: Uses standard mathematical notation and terminology. Follows academic writing conventions.\n- **Conciseness (0.5 pts)**: Avoids redundant explanations while maintaining clarity.\n\nPlease compare the two solutions and determine which one is better overall based on the criteria above.\n\n**Math or Reasoning Problem**:\n##SOURCE##\n\n**Solution A**:\n##A##\n\n**Solution B**:\n##B##\n\nPlease select the better one by responding with either \"A\", \"B\", or \"Tie\".\n\n**Important Notes:**\nOnly give me the answer \"A\", \"B\", or \"Tie\". Do not provide any explanation or annotation or other words.",
    "knowledge_pair_prompt": "You are tasked with comparing two answers of the given multiple-choice question, based on the following criteria:\n\n- **Accuracy (4.0 pts)**: Does the answer factually align with established knowledge in the field?\nExample: A biology answer must follow peer-reviewed scientific consensus.\n- **Logical Consistency (2.5 pts)**: Is the reasoning internally coherent and free of contradictions?\nExample: A philosophy answer shouldn't violate its own premises.\n- **Completeness (2.0 pts)**: Does it address all critical components required by the question?\nExample: A physics problem solution must include units and formulas.\n- **Contextual Relevance (1.0 pts)**: Does it directly address the question's scope and avoid irrelevant tangents?\nExample: A law answer must reference applicable statutes/case law.\n- **Disciplinary Methodology (0.5 pts)**: Does it follow the subject's accepted frameworks/analysis patterns?\nExample: Economics answers should use cost-benefit analysis where appropriate.\n\nPlease compare the two answers and determine which one is better overall based on the criteria above.\n\n**Multiple-choice Question**:\n##SOURCE##\n\n**Answer A**:\n##A##\n\n**Answer B**:\n##B##\n\nPlease select the better one by responding with either \"A\", \"B\", or \"Tie\".\n\n**Important Notes:**\nOnly give me the answer \"A\", \"B\", or \"Tie\". Do not provide any explanation or annotation or other words.",
    "summarization_pair_prompt": "You are tasked with comparing two summarizations of the given article, based on the following criteria:\n\n- **Content Fidelity (4.0 pts)**: Does the summary accurately reflect the key facts, data, and conclusions of the original article without distortion?\nExample: A summary omitting a study’s critical sample size or misrepresenting its conclusions loses fidelity.\n- **Coherence & Structure (2.5 pts)**: Is the summary logically organized and free of contradictions or fragmented ideas?\nExample: A summary jumping haphazardly between topics without causal/time links lacks coherence.\n- **Coverage of Key Points (2.0 pts)**: Does it include all essential elements (e.g., purpose, methods, results, implications)?\nExample: A research article summary missing the methodology section would be incomplete.\n- **Conciseness (1.0 pts)**: Is redundant or trivial information removed while retaining critical content?\nExample: Repeating minor details from the article’s introduction reduces conciseness.\n- **Clarity & Readability (0.5 pts)**: Is the summary free of jargon and grammatically clear for its intended audience?\nExample: Overloading technical terms in a public-facing summary harms readability.\n\nPlease compare the two summarizations and determine which one is better overall based on the criteria above.\n\n**Article**:\n##SOURCE##\n\n**Summarization A**:\n##A##\n\n**Summarization B**:\n##B##\n\nPlease select the better one by responding with either \"A\", \"B\", or \"Tie\".\n\n**Important Notes:**\nOnly give me the answer \"A\", \"B\", or \"Tie\". Do not provide any explanation or annotation or other words."

}
